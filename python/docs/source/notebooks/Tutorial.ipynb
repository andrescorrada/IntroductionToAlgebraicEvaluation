{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9ccc343-0de7-430e-9c2c-9a77de944618",
   "metadata": {},
   "source": [
    "# Tutorial - evaluate three binary classifiers on a test from the UCI Adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf1de6dd-fffc-49a4-8283-9810484cacda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import ntqr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d329c7-1b5b-47c5-b143-b9b02cb2a7c8",
   "metadata": {},
   "source": [
    "There is a data sketch of a test using the UCI Adult dataset that contains the by-label voting counts of three binary classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4222eebc-c683-41aa-a73c-a27d4db166b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_counts = ntqr.uciadult_label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41cfb173-2a82-4f20-b969-13bcbb32c0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': {('a', 'a', 'a'): 715,\n",
      "       ('a', 'a', 'b'): 161,\n",
      "       ('a', 'b', 'a'): 2406,\n",
      "       ('a', 'b', 'b'): 455,\n",
      "       ('b', 'a', 'a'): 290,\n",
      "       ('b', 'a', 'b'): 94,\n",
      "       ('b', 'b', 'a'): 1335,\n",
      "       ('b', 'b', 'b'): 231},\n",
      " 'b': {('a', 'a', 'a'): 271,\n",
      "       ('a', 'a', 'b'): 469,\n",
      "       ('a', 'b', 'a'): 3395,\n",
      "       ('a', 'b', 'b'): 7517,\n",
      "       ('b', 'a', 'a'): 272,\n",
      "       ('b', 'a', 'b'): 399,\n",
      "       ('b', 'b', 'a'): 6377,\n",
      "       ('b', 'b', 'b'): 12455}}\n"
     ]
    }
   ],
   "source": [
    "pprint(labeled_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69ffdd7-f3d8-45b8-a0a3-f292fdecbbc9",
   "metadata": {},
   "source": [
    "In an unsupervised setting, we do not know the true label for any item. All we get to see are the decisions the classifiers made. These are in effect, the sum of the above counts across the different labels. There is a class for operating on the labeled counts that can give us the projected counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d2ceb8b-cab0-4c2c-90b7-9fe3da9f7071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrioLabelVoteCounts(label_vote_counts={'a': {('a', 'a', 'a'): 715,\n",
      "                                             ('a', 'a', 'b'): 161,\n",
      "                                             ('a', 'b', 'a'): 2406,\n",
      "                                             ('a', 'b', 'b'): 455,\n",
      "                                             ('b', 'a', 'a'): 290,\n",
      "                                             ('b', 'a', 'b'): 94,\n",
      "                                             ('b', 'b', 'a'): 1335,\n",
      "                                             ('b', 'b', 'b'): 231},\n",
      "                                       'b': {('a', 'a', 'a'): 271,\n",
      "                                             ('a', 'a', 'b'): 469,\n",
      "                                             ('a', 'b', 'a'): 3395,\n",
      "                                             ('a', 'b', 'b'): 7517,\n",
      "                                             ('b', 'a', 'a'): 272,\n",
      "                                             ('b', 'a', 'b'): 399,\n",
      "                                             ('b', 'b', 'a'): 6377,\n",
      "                                             ('b', 'b', 'b'): 12455}})\n"
     ]
    }
   ],
   "source": [
    "trio_labeled_counts = ntqr.TrioLabelVoteCounts(labeled_counts)\n",
    "pprint(trio_labeled_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827a776-cbde-4679-b9eb-7c2762c673f8",
   "metadata": {},
   "source": [
    "The class TrioLabelVoteCounts can project the counts across labels for us and give us only the vote pattern counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8dcb119-0e5e-4217-8806-c42f6dc9a1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrioVoteCounts(vote_counts={('a', 'a', 'a'): 986,\n",
      "                            ('a', 'a', 'b'): 630,\n",
      "                            ('a', 'b', 'a'): 5801,\n",
      "                            ('a', 'b', 'b'): 7972,\n",
      "                            ('b', 'a', 'a'): 562,\n",
      "                            ('b', 'a', 'b'): 493,\n",
      "                            ('b', 'b', 'a'): 7712,\n",
      "                            ('b', 'b', 'b'): 12686})\n"
     ]
    }
   ],
   "source": [
    "trio_vote_counts = trio_labeled_counts.to_TrioVoteCounts()\n",
    "pprint(trio_vote_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451fd84b-b102-40f7-b967-1fe15c323ba8",
   "metadata": {},
   "source": [
    "The challenge in unsupervised evaluation is to go from these counts back to the by-label counts. Let's see what happens when you use an algebraic evaluation that assumes that the classifiers where error independent on this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd7f951c-e0d8-490d-b35f-17012f826d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "algebraic_eval = ntqr.ErrorIndependentEvaluation(trio_vote_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc811dbf-46f5-45fb-b3e1-3d1d062b5024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11187722681*sqrt(3328641826009)/61316911076911789 + 1/2,\n",
      " 1/2 - 11187722681*sqrt(3328641826009)/61316911076911789]\n"
     ]
    }
   ],
   "source": [
    "ae_eval = algebraic_eval.evaluation_exact\n",
    "pprint(ae_eval[\"'a' prevalence solutions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a63d610-8760-4080-8d87-e9be50907d50",
   "metadata": {},
   "source": [
    "The two possible solutions for the 'a' label prevalence contain an unresolved square root. This means that the error independence assumption is wrong! The three classifiers in the test have non-zero error correlations. But let us see how close this irrational number is to the actual value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44ad7515-a433-4d14-900b-d699d36deb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.832885560346949, 0.16711443965305095]\n"
     ]
    }
   ],
   "source": [
    "ae_evalf = algebraic_eval.evaluation_float\n",
    "pprint(ae_evalf[\"'a' prevalence solutions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c85e67b-7584-4a90-88f3-9d9760fc8afc",
   "metadata": {},
   "source": [
    "The correct evaluation can be computed with the labeled counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "004dd070-e66e-406f-81ee-5029387e123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_eval = ntqr.SupervisedEvaluation(trio_labeled_counts)\n",
    "seval_exact = supervised_eval.evaluation_exact\n",
    "seval_float = supervised_eval.evaluation_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d8678ba-9329-45c1-a0ac-c75e775f4bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.15436186960534173, 'b': 0.8456381303946583}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seval_float[\"prevalence\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec646576-5e6e-4af5-8855-aeede121d70a",
   "metadata": {},
   "source": [
    "So the error independent algebraic evaluation is 16.7% and the true 'a' label prevalence is 15.4%. Not bad. How does majority voting do on this test as an evaluator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61ec73ca-fdf5-4cb6-9bbe-d9bbbfc817e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_voting_eval = ntqr.MajorityVotingEvaluation(trio_vote_counts)\n",
    "mv_eval_exact = majority_voting_eval.evaluation_exact\n",
    "mv_eval_float = majority_voting_eval.evaluation_float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ca97ab-7077-40e7-aea9-94243afa9776",
   "metadata": {},
   "source": [
    "Majority voting does not warn you that the classifiers are actually error correlated since it can only produce rational estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd0fa17b-a634-49ad-a291-9f1bb7c23365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': Fraction(7979, 36842), 'b': Fraction(28863, 36842)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_eval_exact[\"prevalence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc872949-ac44-496b-a9d2-b3a6f9a7e0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.2165734759242169, 'b': 0.7834265240757831}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_eval_float[\"prevalence\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644276ef-3401-4136-812e-073d055d4755",
   "metadata": {},
   "source": [
    "To summarize - the true 'a' label prevalence is 15.4%, algebraic evaluation estimates 16.7% and majority voting 21.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565ffecb-7563-4bd6-a9f6-e1f441f87e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
